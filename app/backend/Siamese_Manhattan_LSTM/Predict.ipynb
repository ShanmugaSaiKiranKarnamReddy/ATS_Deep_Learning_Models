{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XR7bSFt4Bz-E",
    "outputId": "00b8eb16-ed57-4d04-e524-2dc50d73e17f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/content/drive/My Drive/Application Tracking System - Neural Networks/*.py': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/drive/My Drive/Application Tracking System - Neural Networks/*.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "bAmwTwz9B4P0",
    "outputId": "b6df83d2-f0e4-4d94-942c-d8791f9251bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 9904743610955786113, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 735960473595549761\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "-7u3q3mhB6ii",
    "outputId": "cdb689b9-630f-47e8-be3d-04f70ae6ea0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SAJt9hg1B_HJ",
    "outputId": "248dfd7d-ca0b-433d-8cce-d0cd5a274ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Application Tracking System - Neural Networks\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/Application Tracking System - Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WtYVxEyZB_ip",
    "outputId": "2d18731f-cb18-4f73-e48d-25539a91a15c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import re\n",
      "\n",
      "from tensorflow.python.keras import backend as K\n",
      "from tensorflow.python.keras.layers import Layer\n",
      "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
      "\n",
      "from nltk.corpus import stopwords\n",
      "from gensim.models import KeyedVectors\n",
      "\n",
      "import gensim\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import itertools\n",
      "\n",
      "EMBEDDING_FILE = './data/Resume_JD_new_13.w2v'\n",
      "\n",
      "def text_to_word_list(text):\n",
      "    # Pre process and convert texts to a list of words\n",
      "    text = str(text)\n",
      "    text = text.lower()\n",
      "\n",
      "    # Clean the text\n",
      "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
      "    text = re.sub(r\"what's\", \"what is \", text)\n",
      "    text = re.sub(r\"\\'s\", \" \", text)\n",
      "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
      "    text = re.sub(r\"can't\", \"cannot \", text)\n",
      "    text = re.sub(r\"n't\", \" not \", text)\n",
      "    text = re.sub(r\"i'm\", \"i am \", text)\n",
      "    text = re.sub(r\"\\'re\", \" are \", text)\n",
      "    text = re.sub(r\"\\'d\", \" would \", text)\n",
      "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
      "    text = re.sub(r\",\", \" \", text)\n",
      "    text = re.sub(r\"\\.\", \" \", text)\n",
      "    text = re.sub(r\"!\", \" ! \", text)\n",
      "    text = re.sub(r\"\\/\", \" \", text)\n",
      "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
      "    text = re.sub(r\"\\+\", \" + \", text)\n",
      "    text = re.sub(r\"\\-\", \" - \", text)\n",
      "    text = re.sub(r\"\\=\", \" = \", text)\n",
      "    text = re.sub(r\"'\", \" \", text)\n",
      "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
      "    text = re.sub(r\":\", \" : \", text)\n",
      "    text = re.sub(r\" e g \", \" eg \", text)\n",
      "    text = re.sub(r\" b g \", \" bg \", text)\n",
      "    text = re.sub(r\" u s \", \" american \", text)\n",
      "    text = re.sub(r\"\\0s\", \"0\", text)\n",
      "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
      "    text = re.sub(r\"e - mail\", \"email\", text)\n",
      "    text = re.sub(r\"j k\", \"jk\", text)\n",
      "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
      "\n",
      "    text = text.split()\n",
      "\n",
      "    return text\n",
      "\n",
      "\n",
      "def make_w2v_embeddings(df, embedding_dim=300, empty_w2v=False):\n",
      "    vocabs = {}\n",
      "    vocabs_cnt = 0\n",
      "\n",
      "    vocabs_not_w2v = {}\n",
      "    vocabs_not_w2v_cnt = 0\n",
      "\n",
      "    # Stopwords\n",
      "    stops = set(stopwords.words('english'))\n",
      "\n",
      "    # Load word2vec\n",
      "    print(\"Loading word2vec model(it may takes 2-3 mins) ...\")\n",
      "\n",
      "    if empty_w2v:\n",
      "        word2vec = EmptyWord2Vec\n",
      "    else:\n",
      "        word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
      "                    \n",
      "    for index, row in df.iterrows():\n",
      "        # Print the number of embedded sentences.\n",
      "        if index != 0 and index % 1000 == 0:\n",
      "            print(\"{:,} sentences embedded.\".format(index), flush=True)\n",
      "\n",
      "        # Iterate through the text of both questions of the row\n",
      "        for question in ['Resume', 'JD']:\n",
      "\n",
      "            q2n = []  # q2n -> question numbers representation\n",
      "            for word in text_to_word_list(row[question]):\n",
      "                # Check for unwanted words\n",
      "                if word in stops:\n",
      "                    continue\n",
      "\n",
      "                # If a word is missing from word2vec model.\n",
      "                if word not in word2vec.vocab:\n",
      "                    if word not in vocabs_not_w2v:\n",
      "                        vocabs_not_w2v_cnt += 1\n",
      "                        vocabs_not_w2v[word] = 1\n",
      "\n",
      "                # If you have never seen a word, append it to vocab dictionary.\n",
      "                if word not in vocabs:\n",
      "                    vocabs_cnt += 1\n",
      "                    vocabs[word] = vocabs_cnt\n",
      "                    q2n.append(vocabs_cnt)\n",
      "                else:\n",
      "                    q2n.append(vocabs[word])\n",
      "\n",
      "            # Append question as number representation\n",
      "            df.at[index, question + '_n'] = q2n\n",
      "\n",
      "    embeddings = 1 * np.random.randn(len(vocabs) + 1, embedding_dim)  # This will be the embedding matrix\n",
      "    embeddings[0] = 0  # So that the padding will be ignored\n",
      "\n",
      "    # Build the embedding matrix\n",
      "    for word, index in vocabs.items():\n",
      "        if word in word2vec.vocab:\n",
      "            embeddings[index] = word2vec.word_vec(word)\n",
      "    del word2vec\n",
      "\n",
      "    return df, embeddings\n",
      "\n",
      "\n",
      "def split_and_zero_padding(df, max_seq_length):\n",
      "    # Split to dicts\n",
      "    X = {'left': df['Resume_n'], 'right': df['JD_n']}\n",
      "\n",
      "    # Zero padding\n",
      "    for dataset, side in itertools.product([X], ['left', 'right']):\n",
      "        dataset[side] = pad_sequences(dataset[side], padding='pre', truncating='post', maxlen=max_seq_length)\n",
      "\n",
      "    return dataset\n",
      "\n",
      "\n",
      "#  --\n",
      "\n",
      "class ManDist(Layer):\n",
      "    \"\"\"\n",
      "    Keras Custom Layer that calculates Manhattan Distance.\n",
      "    \"\"\"\n",
      "\n",
      "    # initialize the layer, No need to include inputs parameter!\n",
      "    def __init__(self, **kwargs):\n",
      "        self.result = None\n",
      "        super(ManDist, self).__init__(**kwargs)\n",
      "\n",
      "    # input_shape will automatic collect input shapes to build layer\n",
      "    def build(self, input_shape):\n",
      "        super(ManDist, self).build(input_shape)\n",
      "\n",
      "    # This is where the layer's logic lives.\n",
      "    def call(self, x, **kwargs):\n",
      "        self.result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
      "        return self.result\n",
      "\n",
      "    # return output shape\n",
      "    def compute_output_shape(self, input_shape):\n",
      "        return K.int_shape(self.result)\n",
      "\n",
      "\n",
      "class EmptyWord2Vec:\n",
      "    \"\"\"\n",
      "    Just for test use.\n",
      "    \"\"\"\n",
      "    vocab = {}\n",
      "    word_vec = {}\n"
     ]
    }
   ],
   "source": [
    "!cat '/content/drive/My Drive/Application Tracking System - Neural Networks/util.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycfsO41BCEqZ"
   },
   "outputs": [],
   "source": [
    "#load all packages\n",
    "import re\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import gensim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBxyrfg3CNqB"
   },
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    # Pre process and convert texts to a list of words\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dalP-8hsCTHh"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './data/Resume_JD_new_13.w2v'\n",
    "#word2vec embedding\n",
    "def make_w2v_embeddings(df, embedding_dim=300, empty_w2v=False):\n",
    "    vocabs = {}\n",
    "    vocabs_cnt = 0\n",
    "\n",
    "    vocabs_not_w2v = {}\n",
    "    vocabs_not_w2v_cnt = 0\n",
    "\n",
    "    # Stopwords\n",
    "    stops = set(stopwords.words('english'))\n",
    "\n",
    "    # Load word2vec\n",
    "    print(\"Loading word2vec model(it may takes 2-3 mins) ...\")\n",
    "\n",
    "    if empty_w2v:\n",
    "        word2vec = EmptyWord2Vec\n",
    "    else:\n",
    "        word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "                    \n",
    "    for index, row in df.iterrows():\n",
    "        # Print the number of embedded sentences.\n",
    "        if index != 0 and index % 1000 == 0:\n",
    "            print(\"{:,} sentences embedded.\".format(index), flush=True)\n",
    "\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for question in ['Resume', 'JD']:\n",
    "\n",
    "            q2n = []  # q2n -> question numbers representation\n",
    "            for word in text_to_word_list(row[question]):\n",
    "                # Check for unwanted words\n",
    "                if word in stops:\n",
    "                    continue\n",
    "\n",
    "                # If a word is missing from word2vec model.\n",
    "                if word not in word2vec.vocab:\n",
    "                    if word not in vocabs_not_w2v:\n",
    "                        vocabs_not_w2v_cnt += 1\n",
    "                        vocabs_not_w2v[word] = 1\n",
    "\n",
    "                # If you have never seen a word, append it to vocab dictionary.\n",
    "                if word not in vocabs:\n",
    "                    vocabs_cnt += 1\n",
    "                    vocabs[word] = vocabs_cnt\n",
    "                    q2n.append(vocabs_cnt)\n",
    "                else:\n",
    "                    q2n.append(vocabs[word])\n",
    "\n",
    "            # Append question as number representation\n",
    "            df.at[index, question + '_n'] = q2n\n",
    "\n",
    "    embeddings = 1 * np.random.randn(len(vocabs) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "    embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "    # Build the embedding matrix\n",
    "    for word, index in vocabs.items():\n",
    "        if word in word2vec.vocab:\n",
    "            embeddings[index] = word2vec.word_vec(word)\n",
    "    del word2vec\n",
    "\n",
    "    return df, embeddings\n",
    "\n",
    "#zero padding\n",
    "def split_and_zero_padding(df, max_seq_length):\n",
    "    # Split to dicts\n",
    "    X = {'left': df['Resume_n'], 'right': df['JD_n']}\n",
    "\n",
    "    # Zero padding\n",
    "    for dataset, side in itertools.product([X], ['left', 'right']):\n",
    "        dataset[side] = pad_sequences(dataset[side], padding='pre', truncating='post', maxlen=max_seq_length)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "#  --\n",
    "#Manhattan distance\n",
    "class ManDist(Layer):\n",
    "    \"\"\"\n",
    "    Keras Custom Layer that calculates Manhattan Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the layer, No need to include inputs parameter!\n",
    "    def __init__(self, **kwargs):\n",
    "        self.result = None\n",
    "        super(ManDist, self).__init__(**kwargs)\n",
    "\n",
    "    # input_shape will automatic collect input shapes to build layer\n",
    "    def build(self, input_shape):\n",
    "        super(ManDist, self).build(input_shape)\n",
    "\n",
    "    # This is where the layer's logic lives.\n",
    "    def call(self, x, **kwargs):\n",
    "        self.result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
    "        return self.result\n",
    "\n",
    "    # return output shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return K.int_shape(self.result)\n",
    "\n",
    "\n",
    "class EmptyWord2Vec:\n",
    "    \"\"\"\n",
    "    Just for test use.\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    word_vec = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcXEWkuJCt44"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from util import make_w2v_embeddings\n",
    "from util import split_and_zero_padding\n",
    "from util import ManDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZAhDj0ZKLec"
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client.Applications\n",
    "collection = db.sample_1\n",
    "\n",
    "# print(\"Enter Resume File pathname\")\n",
    "# for filepath in list(glob.iglob(input())):\n",
    "#     if filepath.endswith(\".jpg\") or filepath.endswith(\".png\"):\n",
    "#         img = Image.open(filepath)\n",
    "#         text1 = terr.image_to_string(img)\n",
    "#         text = text1.lower()\n",
    "#         tx = \" \".join(text.split('\\n'))\n",
    "#         print(tx)\n",
    "#         collection.insert_one(tx)\n",
    "#     elif filepath.endswith(\".pdf\") or filepath.endswith(\".docx\"):\n",
    "#         data = ResumeParser(filepath).get_extracted_data()\n",
    "#         data_mongo = data\n",
    "#         collection.insert_one(data_mongo)\n",
    "num_doc = collection.find().count()\n",
    "# print(f'Number of documents inserted in mongodb are:{num_doc}')\n",
    "resume_skills_work = collection.find({},{'_id': 0, 'skills':1,  \n",
    "                 'experience': 1})\n",
    "test_df1 = pd.DataFrame(list(resume_skills_work))\n",
    "test_df1['Resume'] = test_df1['skills'] + test_df1['experience']\n",
    "test_df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FiekiclECw7P",
    "outputId": "9e551b7d-d68e-45d8-db02-1da100b8d130"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume</th>\n",
       "      <th>JD</th>\n",
       "      <th>Score</th>\n",
       "      <th>Resume_n</th>\n",
       "      <th>JD_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Worked with advance web development technologi...</td>\n",
       "      <td>Worked with advance web development technologi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Worked with advance web development technologi...</td>\n",
       "      <td>Worked with advance web development technologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maximized use of Events and promises in ES6 an...</td>\n",
       "      <td>Maximized use of Events and promises in ES6 an...</td>\n",
       "      <td>5</td>\n",
       "      <td>Maximized use of Events and promises in ES6 an...</td>\n",
       "      <td>Maximized use of Events and promises in ES6 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Developed Drag-gable and Re-sizable modals usi...</td>\n",
       "      <td>Developed Drag-gable and Re-sizable modals usi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Developed Drag-gable and Re-sizable modals usi...</td>\n",
       "      <td>Developed Drag-gable and Re-sizable modals usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enforced Agile and Scrum development methodolo...</td>\n",
       "      <td>Enforced Agile and Scrum development methodolo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Enforced Agile and Scrum development methodolo...</td>\n",
       "      <td>Enforced Agile and Scrum development methodolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Developed sound knowledge on React, Redux for ...</td>\n",
       "      <td>Developed sound knowledge on React, Redux for ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Developed sound knowledge on React, Redux for ...</td>\n",
       "      <td>Developed sound knowledge on React, Redux for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worked with advance web development technologi...</td>\n",
       "      <td>Strong experience in JavaScript, ideally ES6 o...</td>\n",
       "      <td>5</td>\n",
       "      <td>Worked with advance web development technologi...</td>\n",
       "      <td>Strong experience in JavaScript, ideally ES6 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Validated customer interface requirements and ...</td>\n",
       "      <td>4+ years of experience with customer facing we...</td>\n",
       "      <td>5</td>\n",
       "      <td>Validated customer interface requirements and ...</td>\n",
       "      <td>4+ years of experience with customer facing we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Updated versions of React, React-Router.</td>\n",
       "      <td>Experience in building single page application...</td>\n",
       "      <td>5</td>\n",
       "      <td>Updated versions of React, React-Router.</td>\n",
       "      <td>Experience in building single page application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Introduced Ag-Grid package which can plot mill...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Introduced Ag-Grid package which can plot mill...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Worked with advance web development technologi...</td>\n",
       "      <td>Familiarity with ES6 and newer versions of Jav...</td>\n",
       "      <td>5</td>\n",
       "      <td>Worked with advance web development technologi...</td>\n",
       "      <td>Familiarity with ES6 and newer versions of Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mastered Data Structures and Algorithms to cal...</td>\n",
       "      <td>A constant desire to grow, learn, and explore ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Mastered Data Structures and Algorithms to cal...</td>\n",
       "      <td>A constant desire to grow, learn, and explore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Added hooks in the project and moved some clas...</td>\n",
       "      <td>Build reusable modules for both client and ser...</td>\n",
       "      <td>4</td>\n",
       "      <td>Added hooks in the project and moved some clas...</td>\n",
       "      <td>Build reusable modules for both client and ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Added hooks in the project and moved some clas...</td>\n",
       "      <td>Demonstrated passion for building comprehensiv...</td>\n",
       "      <td>4</td>\n",
       "      <td>Added hooks in the project and moved some clas...</td>\n",
       "      <td>Demonstrated passion for building comprehensiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>React Developer | ClearC2 Inc - Coppell, TX12/...</td>\n",
       "      <td>3 to 8 years of relevant work experience in Ty...</td>\n",
       "      <td>5</td>\n",
       "      <td>React Developer | ClearC2 Inc - Coppell, TX12/...</td>\n",
       "      <td>3 to 8 years of relevant work experience in Ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>University of Illinois At Springfield - Spring...</td>\n",
       "      <td>BS/MS in Computer Science or similar</td>\n",
       "      <td>5</td>\n",
       "      <td>University of Illinois At Springfield - Spring...</td>\n",
       "      <td>BS/MS in Computer Science or similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Used File-Saver for BLOB downloads, React-Char...</td>\n",
       "      <td>Construct visualizations that are able to depi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Used File-Saver for BLOB downloads, React-Char...</td>\n",
       "      <td>Construct visualizations that are able to depi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Developed quality Web Design mockups using UX ...</td>\n",
       "      <td>Work with product team and graphic designers</td>\n",
       "      <td>5</td>\n",
       "      <td>Developed quality Web Design mockups using UX ...</td>\n",
       "      <td>Work with product team and graphic designers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Used GIMP open source alternative to photoshop...</td>\n",
       "      <td>Learn and understand user interactions</td>\n",
       "      <td>5</td>\n",
       "      <td>Used GIMP open source alternative to photoshop...</td>\n",
       "      <td>Learn and understand user interactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Developed a web app for show casing how this t...</td>\n",
       "      <td>Develop a flexible and well-structured front-e...</td>\n",
       "      <td>5</td>\n",
       "      <td>Developed a web app for show casing how this t...</td>\n",
       "      <td>Develop a flexible and well-structured front-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tested REST endpoints using POSTMAN.</td>\n",
       "      <td>Experience with REST API's</td>\n",
       "      <td>5</td>\n",
       "      <td>Tested REST endpoints using POSTMAN.</td>\n",
       "      <td>Experience with REST API's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GitHub and Git Lab as version control systems.</td>\n",
       "      <td>Git knowledge is a plus</td>\n",
       "      <td>5</td>\n",
       "      <td>GitHub and Git Lab as version control systems.</td>\n",
       "      <td>Git knowledge is a plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>University of Illinois At Springfield - Spring...</td>\n",
       "      <td>Bachelor’s degree in any STEM program (or equi...</td>\n",
       "      <td>5</td>\n",
       "      <td>University of Illinois At Springfield - Spring...</td>\n",
       "      <td>Bachelor’s degree in any STEM program (or equi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Enforced Agile and Scrum development methodolo...</td>\n",
       "      <td>Participate in agile development</td>\n",
       "      <td>5</td>\n",
       "      <td>Enforced Agile and Scrum development methodolo...</td>\n",
       "      <td>Participate in agile development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Resume  ...                                               JD_n\n",
       "0   Worked with advance web development technologi...  ...  Worked with advance web development technologi...\n",
       "1   Maximized use of Events and promises in ES6 an...  ...  Maximized use of Events and promises in ES6 an...\n",
       "2   Developed Drag-gable and Re-sizable modals usi...  ...  Developed Drag-gable and Re-sizable modals usi...\n",
       "3   Enforced Agile and Scrum development methodolo...  ...  Enforced Agile and Scrum development methodolo...\n",
       "4   Developed sound knowledge on React, Redux for ...  ...  Developed sound knowledge on React, Redux for ...\n",
       "5   Worked with advance web development technologi...  ...  Strong experience in JavaScript, ideally ES6 o...\n",
       "6   Validated customer interface requirements and ...  ...  4+ years of experience with customer facing we...\n",
       "7            Updated versions of React, React-Router.  ...  Experience in building single page application...\n",
       "8   Introduced Ag-Grid package which can plot mill...  ...                                                NaN\n",
       "9   Worked with advance web development technologi...  ...  Familiarity with ES6 and newer versions of Jav...\n",
       "10  Mastered Data Structures and Algorithms to cal...  ...  A constant desire to grow, learn, and explore ...\n",
       "11  Added hooks in the project and moved some clas...  ...  Build reusable modules for both client and ser...\n",
       "12  Added hooks in the project and moved some clas...  ...  Demonstrated passion for building comprehensiv...\n",
       "13  React Developer | ClearC2 Inc - Coppell, TX12/...  ...  3 to 8 years of relevant work experience in Ty...\n",
       "14  University of Illinois At Springfield - Spring...  ...               BS/MS in Computer Science or similar\n",
       "15  Used File-Saver for BLOB downloads, React-Char...  ...  Construct visualizations that are able to depi...\n",
       "16  Developed quality Web Design mockups using UX ...  ...       Work with product team and graphic designers\n",
       "17  Used GIMP open source alternative to photoshop...  ...             Learn and understand user interactions\n",
       "18  Developed a web app for show casing how this t...  ...  Develop a flexible and well-structured front-e...\n",
       "19               Tested REST endpoints using POSTMAN.  ...                         Experience with REST API's\n",
       "20     GitHub and Git Lab as version control systems.  ...                            Git knowledge is a plus\n",
       "21  University of Illinois At Springfield - Spring...  ...  Bachelor’s degree in any STEM program (or equi...\n",
       "22  Enforced Agile and Scrum development methodolo...  ...                   Participate in agile development\n",
       "\n",
       "[23 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TEST_CSV = '/content/drive/My Drive/Application Tracking System - Neural Networks/MLSTM_TEST_1.xlsx'\n",
    "test_df3 = pd.read_excel(TEST_CSV)\n",
    "for q in ['Resume', 'JD']:\n",
    "    test_df3[q + '_n'] = test_df3[q]\n",
    "test_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "6GQP_o7sHgGt",
    "outputId": "31ddefe2-3489-47fc-863b-4ea52581552c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpOi6y3oIS-p"
   },
   "outputs": [],
   "source": [
    "use_w2v = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ohe8OXZiCzbX",
    "outputId": "e77470f1-b202-4ea7-dcd3-fe40e9ff490b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model(it may takes 2-3 mins) ...\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "max_seq_length = 70\n",
    "test_df3, embeddings = make_w2v_embeddings(test_df3, embedding_dim=embedding_dim, empty_w2v=use_w2v)\n",
    "\n",
    "# Split to dicts and append zero padding.\n",
    "X_test = split_and_zero_padding(test_df3, max_seq_length)\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert X_test['left'].shape == X_test['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "qF0JQIdjHbSV",
    "outputId": "0f253c36-2044-439a-e5f3-0ada1b78e967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 64)           2111520     input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "man_dist_5 (ManDist)            (None, 1)            0           sequential_5[0][0]               \n",
      "                                                                 sequential_5[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,111,520\n",
      "Trainable params: 2,111,520\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./data/SiameseLSTM_new20.h5', custom_objects={'ManDist': ManDist})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "MCmNFKL5IaS4",
    "outputId": "03e89203-0e1e-4a35-eadb-bb5bd101cddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 5\n",
      "Score: 5\n",
      "Score: 5\n",
      "Score: 5\n",
      "Score: 5\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 2\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n",
      "Score: 1\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([X_test['left'], X_test['right']]) * 100\n",
    "prediction\n",
    "for i in prediction:\n",
    "    if 90 <= i <= 100:\n",
    "        print(\"Score:\",5)\n",
    "    elif 70 <= i < 90:\n",
    "        print(\"Score:\", 4)\n",
    "    elif 55 <= i < 70:\n",
    "        print(\"Score:\", 3)\n",
    "    elif 40 <= i <55:\n",
    "        print(\"Score:\", 2)\n",
    "    else:\n",
    "        print(\"Score:\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01mqB8sSVUhQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWbOn0M3IfSm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XNr7ELdXexL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Predict",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
